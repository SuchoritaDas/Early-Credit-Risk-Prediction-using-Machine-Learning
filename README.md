# Early-Credit-Risk-Prediction-using-Machine-Learning

ğŸ“Œ Project Overview

This project demonstrates an end-to-end Machine Learning workflow to build an Early Credit Risk Prediction system using historical loan applicant data.
The goal is to identify risky loan applicants early, before loan approval, so that financial institutions can make better, data-driven decisions and reduce potential losses.

The project is designed to be:

Beginner-friendly
Explainable to non-technical stakeholders
Aligned with real-world banking use cases
Built using free tools and open datasets

ğŸ¯ Problem Definition & AI Framing
ğŸ” Business Problem

Financial institutions process thousands of loan applications daily.
Approving loans for high-risk applicants can lead to loan defaults, which directly impact business profitability.
Traditional rule-based systems (fixed income thresholds, rigid credit rules):
Fail to capture complex risk patterns
Do not adapt to changing borrower behavior
Produce binary decisions without confidence levels

ğŸ§  Why AI is Needed

Machine Learning is used because:
Credit risk depends on multiple interacting factors
Risk patterns are not linear
ML models can produce probability-based risk scores, not just yes/no decisions

ğŸ¯ Objective

To build a Machine Learning system that:
Predicts whether a loan applicant is high risk or low risk
Provides a probability of default
Supports early decision-making before loan approval

ğŸ”¢ ML Framing

Problem Type: Binary Classification

Inputs: Applicant & loan attributes

Output:

Risk Prediction (0 = Low Risk, 1 = High Risk)
Probability of Default

ğŸ—‚ï¸ End-to-End Project Architecture
Raw Loan Data
      â†“
Bronze Layer (Raw Storage)
      â†“
Silver Layer (Cleaned & Validated Data)
      â†“
ML Preparation (Feature Engineering)
      â†“
Model Training & Evaluation
      â†“
Risk Prediction & Probability Scores

This architecture follows modern data + AI best practices.

ğŸ¥‰ Bronze Layer â€“ Raw Data Ingestion
ğŸ¯ Purpose

The Bronze layer stores the raw dataset exactly as received, without modifying its content.

Key Characteristics

No cleaning
No transformation
No ML logic

Why This Matters

Preserves original data for traceability
Enables reproducibility
Acts as a single source of truth

ğŸ‘‰ Think of the Bronze layer as safe storage of facts.

ğŸ¥ˆ Silver Layer â€“ Data Cleaning & Validation
ğŸ¯ Purpose

Prepare reliable and realistic data for Machine Learning.

Key Actions

Handle missing values in critical columns
Remove invalid records (e.g., zero or negative income)
Ensure realistic loan amounts and interest rates
Standardize schema
Rename target column to label

Why This Matters

Machine Learning models are highly sensitive to bad data.
This step ensures the model learns from trustworthy information.

ğŸ¤– ML Preparation â€“ Feature Engineering
ğŸ¯ Purpose

Convert business data into a machine-readable format.

Step-by-Step Breakdown

1ï¸âƒ£ Handling Missing Values

Only rows with complete, meaningful information are retained.

2ï¸âƒ£ Encoding Categorical Variables

Text-based fields such as:

Loan intent
Loan grade
Home ownership are converted into numeric values using StringIndexer.

3ï¸âƒ£ Feature Assembly

All numerical and encoded categorical features are combined into a single vector using VectorAssembler.
Final ML Dataset Contains
features â†’ Vector of all input features
label â†’ Target variable (credit risk outcome)
This structure is required by Spark ML algorithms.

âš™ï¸ Model Selection & Technical Reasoning
ğŸ¤– Model Used: Logistic Regression

Why Logistic Regression?

Industry-standard baseline for credit risk
Interpretable and transparent
Produces probability scores
Suitable for regulated financial environments
Limitations

May not capture highly complex non-linear patterns

Chosen intentionally for explainability and stability

ğŸ§ª Model Training Strategy

Dataset split into:
70% Training Data
30% Test Data
Ensures fair evaluation on unseen data
Prevents overfitting

ğŸ“Š Model Evaluation & Metrics
Metric Used: AUC (Area Under ROC Curve)
Why AUC?

Measures how well the model separates high-risk vs low-risk applicants

Robust to class imbalance

Widely accepted in financial risk modeling

Interpretation

AUC = 0.5 â†’ Random guessing
AUC = 1.0 â†’ Perfect separation
Higher AUC â†’ Better risk discrimination
The model achieved a strong AUC score, indicating effective risk separation.

ğŸ“ˆ Model Outputs (Business-Focused)

For each loan applicant, the model produces:

| Output      | Description           |
| ----------- | --------------------- |
| Prediction  | High Risk / Low Risk  |
| Probability | Likelihood of default |
| Confidence  | Model certainty       |

Example (Non-Technical Explanation)
â€œThis applicant has an 82% probability of default, so the model flags them as high risk.â€


ğŸ§  AI Innovation & Insight Generation (Most Important)

This project goes beyond just training a model.

Key Innovation

Instead of using only binary predictions, the system outputs probability-based risk scores.
Risk Segmentation (Conceptual)
Low Risk â†’ Probability < 0.3
Medium Risk â†’ 0.3 â€“ 0.6
High Risk â†’ > 0.6

Why This Matters

Enables proactive risk management
Supports tiered decision-making
Converts ML output into actionable insights

This transforms predictions into business decisions, not just numbers.

ğŸ—„ï¸ Database â†” AI Workflow

Data loaded from Delta tables
Cleaned and validated through structured layers
Features extracted directly from database
ML consumes table-based data
Predictions generated from database-driven pipeline

This ensures:

Reproducibility
Traceability
Clean AI workflow integration

ğŸ’¼ Business Impact & Practical Use

This system can help:
Reduce loan defaults
Improve credit decision quality
Enable early risk detection
Support data-driven lending strategies

ğŸ“Œ Key Takeaways

End-to-end AI pipeline implemented
Clear separation of data layers
Explainable ML model
Business-focused decision support
Beginner-friendly and interview-ready

ğŸš€ Future Enhancements

Advanced models (Random Forest, XGBoost)
Hyperparameter tuning
Fairness & bias analysis
Automated retraining
Deployment as a scoring service

ğŸ¤ How to Present This Project

Explain problem â†’ data â†’ ML â†’ decision
Show predictions & probabilities
Explain AUC in simple terms
Highlight early risk detection

ğŸ Final Note
This project demonstrates how raw data can be transformed into real-world decisions using Machine Learning, while maintaining explainability and business relevance.
